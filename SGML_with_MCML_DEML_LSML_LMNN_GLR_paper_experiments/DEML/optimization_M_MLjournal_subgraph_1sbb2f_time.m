function [ class_temp_binary, class_temp, ...
    GT_obj_all, obj_all, error_iter,obj_vec,time_vec] = ...
    optimization_M_MLjournal_subgraph_1sbb2f_time( class_test, ...
    feature_train_test, ...
    initial_label, ...
    initial_label_index, ...
    class_train_test, ...
    class_i, ...
    class_j, ...
    S_upper,...
    rho,...
    epsilon,...
    proportion_factor,...
    proportion_threshold,...
    tol_set_prepro,...
    tol_main,...
    tol_diagonal,...
    tol_offdiagonal)

%% proposed method: FULL + Diagonal and one row/column of Off-diagonal + FULL
GT_obj_all = 0;
obj_all = 0;
error_iter = 0;
%% check error rate before metric learning starts
[n_sample, n_feature]= size(feature_train_test); %get the number of samples and the number of features
% M = zeros(n_feature);
% M(logical(eye(n_feature)))=S_upper/n_feature;
% [ L ] = optimization_M_set_L_Mahalanobis_tt( feature_train_test, M ); % full observation
% 
% cvx_begin
% variable x(n_sample,1);
% minimize(x'*L*x)
% subject to
% x(initial_label_index) == class_train_test(initial_label_index);
% cvx_end
% 
% x_valid = sign(x);
% 
% diff_label = x_valid - class_train_test;
% error_classifier = size(find(diff_label~=0),1)*size(find(diff_label~=0),2)/size(class_test,1);
% 
% disp(['objective before metric learning : ' num2str(x_valid'*L*x_valid)]);
% disp(['error rate before metric learning : ' num2str(error_classifier)]);

%% check error rate before metric learning ends

partial_feature = feature_train_test(initial_label_index,:);
partial_observation = class_train_test(initial_label_index);
partial_sample=length(partial_observation);

%% lobpcg random control starts
lobpcg_random_control=0;

%% lobpcg random control ends
tol_golden_search=1e-0;
run_t=1;
time_vec=zeros(run_t,1);
obj_vec=zeros(run_t,1);
GS_or_NR=2;
max_iter=1e3;

for time_i=1:run_t

    tStart=tic;
    
    %% numbers that are to be used
    nv_full=n_feature+(n_feature*(n_feature-1))/2;
    nv_od=2*n_feature-1;
    zz=logical(tril(ones(n_feature),-1));
    

    options = optimoptions('linprog','Display','none','Algorithm','interior-point');
    options.OptimalityTolerance = 1e-2;
    options.ConstraintTolerance = 1e-4;
    
    M=optimization_M_initialization(n_feature,1);
    dia_idx=find(M==diag(M));
    
    num_list=1:n_feature;
    [D,length_D] = get_S_and_D(partial_sample, partial_feature, partial_observation);
    
    initial_objective=dml_obj(M, D);
    disp(['initial = ' num2str(initial_objective)]);
    
    %% 19-NOV-2019 assign BLUE/RED league for the nodes starts
    
    % BLUE is 1
    % RED is -1
    % initialize the graph as blue-red-blue-red
    
    league_vec = ones(n_feature,1);
    league_vec(2:2:end)=-1;
    
    %% 19-NOV-2019 assign BLUE/RED league for the nodes ends
    
    bins=ones(1,n_feature); % connected graph
    
    rng(lobpcg_random_control);
    [M_current_eigenvector,~] = ...
        optimization_M_lobpcg(randn(n_feature,1),M,1e-12,200);
    %scaling_matrix_0 = diag(1./M_current_eigenvector(:,1));
    %scaling_matrix_0_inv = diag(M_current_eigenvector(:,1));
    %scaled_M = scaling_matrix_0 * M * scaling_matrix_0_inv;
    %scaled_factors = scaling_matrix_0 * ones(n_feature) * scaling_matrix_0_inv;
    fv0=M_current_eigenvector(:,1);
    scaled_M = (1./fv0) .* M .* fv0';
    scaled_factors = (1./fv0) .* ones(n_feature) .* fv0';
    
    t_obo=tic;
    
    %     tol_BCD=Inf;
    %     while tol_BCD>1e-5
    %         league_vec0=league_vec;
    
    total_bcd=0;
    [LP_A_sparse_i,LP_A_sparse_j,LP_A_sparse_s,LP_b,LP_lb,LP_ub] = optimization_M_LP_A_setting(n_feature,rho);
    obj_f=initial_objective;
    
    tol_NR=5e-1;
    tol_GD=5e-1;
    
    for BCD = 1:n_feature
        tbcd=tic;
        remaining_idx=1:n_feature;
        remaining_idx(BCD)=[];
        
        %if flag==0
        [ G ] = dml_gradient(...
            M, ...
            D, ...
            n_feature, ...
            nv_od, ...
            BCD, ...
            remaining_idx,...
            length_D);
        G=-G;

        %disp('touch');
        %end
        %G=[2*Gfull(remaining_idx,BCD);diag(Gfull)];
        
        %% BLUE or RED starts
        Ms_off_diagonal = scaled_M(remaining_idx,remaining_idx);
        %scaled_factors_v = scaled_factors(remaining_idx,BCD);
        scaled_factors_h = scaled_factors(BCD,remaining_idx);

        %Ms_off_diagonal(logical(eye(n_feature-1))) = 0;
        
        %% try BLUE league on NODE BCD
        league_vec_temp = league_vec;
        league_vec_temp(BCD) = 1; % BLUE is 1
        league_vec_remaining = league_vec_temp;
        league_vec_remaining(BCD) = [];
        
        [M_blue,...
            scaled_M_blue,...
            scaled_factors_blue,...
            M_current_eigenvector_blue,...
            min_obj_blue,...
            bins_blue,...
            num_list_blue,...
            LP_A_sparse_i,...
            LP_A_sparse_j,...
            LP_A_sparse_s,...
            LP_b,...
            LP_lb,...
            LP_ub,...
            LP_Aeq,...
            LP_beq,...
            zero_mask,...
            scaler_v,...
            remaining_idx,...
            lu_bound_idx] = optimization_M_Block_ns_cell_MLjournal_subgraph_gs_ws(1,league_vec,league_vec_temp,league_vec_remaining,...
            scaled_factors_h,...
            Ms_off_diagonal,...
            n_feature,...
            G,...
            M,...
            BCD,...
            remaining_idx,...
            M_current_eigenvector,...
            rho,...
            S_upper,...
            scaled_M,...
            scaled_factors,...
            bins,...
            obj_f,...
            tol_golden_search,...
            nv_od,...
            zz,...
            num_list,...
            D,...
            options,...
            LP_A_sparse_i,...
            LP_A_sparse_j,...
            LP_A_sparse_s,...
            LP_b,...
            LP_lb,...
            LP_ub,...
            dia_idx,...
            tol_NR,...
            tol_GD,...
            length_D,...
            GS_or_NR,...
            max_iter);
        
        %% try RED league on NODE BCD
        league_vec_temp(BCD) = -1; % RED is -1
        
        [M_red,...
            scaled_M_red,...
            scaled_factors_red,...
            M_current_eigenvector_red,...
            min_obj_red,...
            bins_red,...
            num_list_red] = optimization_M_Block_ns_cell_MLjournal_subgraph_gs_ws2(-1,league_vec,league_vec_temp,league_vec_remaining,...
            scaled_factors_h,...
            n_feature,...
            G,...
            M,...
            BCD,...
            remaining_idx,...
            M_current_eigenvector,...
            rho,...
            S_upper,...
            scaled_M,...
            scaled_factors,...
            bins,...
            obj_f,...
            tol_golden_search,...
            nv_od,...
            zz,...
            num_list,...
            D,...
            LP_A_sparse_i,...
            LP_A_sparse_j,...
            LP_A_sparse_s,...
            LP_b,...
            LP_lb,...
            LP_ub,...
            LP_Aeq,...
            LP_beq,...
            zero_mask,...
            scaler_v,...
            lu_bound_idx,...
            options,...
            dia_idx,...
            tol_NR,...
            tol_GD,...
            length_D,...
            GS_or_NR,...
            max_iter);
        
        if min_obj_red > min_obj_blue
            M = M_red;
            scaled_M = scaled_M_red;
            scaled_factors = scaled_factors_red;
            M_current_eigenvector = M_current_eigenvector_red;
            league_vec(BCD) = -1;
            bins = bins_red;
            num_list=num_list_red;
            obj_f=min_obj_red;
        end
        if min_obj_red < min_obj_blue
            M = M_blue;
            scaled_M = scaled_M_blue;
            scaled_factors = scaled_factors_blue;
            M_current_eigenvector = M_current_eigenvector_blue;
            league_vec(BCD) = 1;
            bins = bins_blue;
            num_list=num_list_blue;
            obj_f=min_obj_blue;
        end
        %% BLUE or RED ends
        total_bcd=total_bcd+toc(tbcd);
        %disp(['BCD: ' num2str(BCD) ' obj: ' num2str(obj_f) ' total_bcd: ' num2str(total_bcd)]);
    end
    %         current_objective = dml_obj(M, D);
    %         tol_BCD=norm(current_objective-initial_objective);
    %         disp(['one pass of BCD = ' num2str(current_objective)]);
    %         disp(['color difference = ' num2str(sum(abs(league_vec-league_vec0)))]);
    %         initial_objective=current_objective;
    %     end
    
    toc(t_obo);
    t_full=tic;
    
    [ G ] = dml_gradient(...
        M, ...
        D, ...
        n_feature, ...
        nv_full, ...
        0, ...
        0,...
        length_D);
    
    G=-G;
    
    tol_NR=5e-1;
    tol_GD=5e-1;
    
    [M] = optimization_M_ns_cell_MLjournal_subgraph_FULL_gs_ws(league_vec,...
        scaled_factors,...
        n_feature,...
        G,...
        M,...
        rho,...
        tol_golden_search,...
        obj_f,...
        S_upper,...
        nv_full,...
        zz,...
        D,...
        options,...
        dia_idx,...
        tol_NR,...
        tol_GD,...
        length_D,...
        GS_or_NR,...
        max_iter);
    
    toc(t_full);
    current_objective = dml_obj(M, D);
    time_vec(time_i)=toc(tStart);
    obj_vec(time_i)=current_objective;
    disp(['mineig = ' num2str(min(eig(M)))]);
    disp(['converged = ' num2str(current_objective)]);
    disp(['total time = ' num2str(time_vec(time_i))]);

end

disp(['time_vec mean: ' num2str(mean(time_vec)) ' std:' num2str(std(time_vec))]);
disp(['obj_vec mean: ' num2str(mean(obj_vec)) ' std:' num2str(std(obj_vec))]);

% [ L ] = optimization_M_set_L_Mahalanobis_tt( feature_train_test, M ); % full observation
% 
% % knn_size = 5;
% % %========KNN classifier starts========
% % fl = class_train_test(initial_label_index);
% % fl(fl == -1) = 0;
% % x = KNN(fl, feature_train_test(initial_label_index,:), sqrtm(M), knn_size, feature_train_test(~initial_label_index,:));
% % x(x==0) = -1;
% % x_valid = class_train_test;
% % x_valid(~initial_label_index) = x;
% % %=========KNN classifier ends=========
% 
% %=======Graph classifier starts=======
% cvx_begin
% variable x(n_sample,1);
% minimize(x'*L*x)
% subject to
% x(initial_label_index) == class_train_test(initial_label_index);
% cvx_end
% 
% x_valid = sign(x);
% %========Graph classifier ends========
% 
% diff_label = x_valid - class_train_test;
% error_classifier = size(find(diff_label~=0),1)*size(find(diff_label~=0),2)/size(class_test,1);
% disp(['objective after metric learning : ' num2str(x_valid'*L*x_valid)]);
% disp(['error rate after metric learning : ' num2str(error_classifier)]);
% 
% class_temp_binary = sign(x_valid);
% class_temp_binary(initial_label_index) = [];
% 
% class_temp = zeros(size(class_temp_binary,1),size(class_temp_binary,2));
% class_temp(class_temp_binary==1) = class_i;
% class_temp(class_temp_binary==-1) = class_j;

class_temp_binary=class_train_test;
class_temp_binary(initial_label_index) = [];
class_temp=class_temp_binary;
end