function [ obj_vec,time_vec,error_classifier] = ...
    optimization_M_MLjournal_subgraph_1sbb2f_time_classification( class_test, ...
    feature_train_test, ...
    initial_label_index, ...
    class_train_test, ...
    class_i, ...
    class_j, ...
    S_upper,...
    rho,...
    classifier_i)

%% check error rate before metric learning starts
[n_sample, n_feature]= size(feature_train_test); %get the number of samples and the number of features

M = eye(n_feature);

[ L ] = optimization_M_set_L_Mahalanobis_tt( feature_train_test, M ); % full observation

if classifier_i==1 % 3-NN classifier
 knn_size = 3;
%========KNN classifier starts========
fl = class_train_test(initial_label_index);
fl(fl == -1) = 0;
x = KNN(fl, feature_train_test(initial_label_index,:), sqrtm(full(M)), knn_size, feature_train_test(~initial_label_index,:));
x(x==0) = -1;
x_valid = class_train_test;
x_valid(~initial_label_index) = x;
%=========KNN classifier ends=========   
elseif classifier_i==2 % Mahalanobis classifier
%=======Mahalanobis classifier starts========
[m,X] = ...
    mahalanobis_classifier_variables(...
    feature_train_test,...
    class_train_test,...
    initial_label_index);
z=mahalanobis_classifier(m,M,X);
x_valid=class_train_test;
x_valid(~initial_label_index)=z;
%========Mahalanobis classifier ends=========    
else % GLR-based classifier
%=======Graph classifier starts=======
cvx_begin
variable x(n_sample,1);
minimize(x'*L*x)
subject to
x(initial_label_index) == class_train_test(initial_label_index);
cvx_end
x_valid = sign(x);
%========Graph classifier ends========    
end

diff_label = x_valid - class_train_test;
error_classifier = size(find(diff_label~=0),1)*size(find(diff_label~=0),2)/size(class_test,1);

disp(['objective before metric learning : ' num2str(x_valid'*L*x_valid)]);
disp(['error rate before metric learning : ' num2str(error_classifier)]);

%% check error rate before metric learning ends

partial_feature = feature_train_test(initial_label_index,:);
partial_observation = class_train_test(initial_label_index);
partial_sample=length(partial_observation);





%% lobpcg random control starts
lobpcg_random_control=0;

%% lobpcg random control ends
tol_golden_search=1e-0;
run_t=1;
time_vec=zeros(run_t,1);
obj_vec=zeros(run_t,1);
GS_or_NR=2;
max_iter=1e3;
for time_i=1:run_t
    
    tStart=tic;
    
    %% numbers that are to be used
    nv_full=n_feature+(n_feature*(n_feature-1))/2;
    nv_od=2*n_feature-1;
    zz=logical(tril(ones(n_feature),-1));
    
    options = optimoptions('linprog','Display','none','Algorithm','interior-point');
    options.OptimalityTolerance = 1e-2;
    options.ConstraintTolerance = 1e-4;
    
    M=optimization_M_initialization(n_feature,1);
    dia_idx=find(M==diag(M));
    
    num_list=1:n_feature;
    [c,y] = optimization_M_cy(partial_feature,partial_observation,partial_sample,n_feature);
    
    [ L ] = optimization_M_set_L_Mahalanobis( partial_sample, c, M );
    initial_objective = partial_observation' * L * partial_observation;
    disp(['initial = ' num2str(initial_objective)]);
    
    %% 19-NOV-2019 assign BLUE/RED league for the nodes starts
    
    % BLUE is 1
    % RED is -1
    % initialize the graph as blue-red-blue-red
    
    league_vec = ones(n_feature,1);
    league_vec(2:2:end)=-1;
    
    %% 19-NOV-2019 assign BLUE/RED league for the nodes ends
    
    bins=ones(1,n_feature); % connected graph
    
    rng(lobpcg_random_control);
    [M_current_eigenvector,~] = ...
        optimization_M_lobpcg(randn(n_feature,1),M,1e-12,200);
    %scaling_matrix_0 = diag(1./M_current_eigenvector(:,1));
    %scaling_matrix_0_inv = diag(M_current_eigenvector(:,1));
    %scaled_M = scaling_matrix_0 * M * scaling_matrix_0_inv;
    %scaled_factors = scaling_matrix_0 * ones(n_feature) * scaling_matrix_0_inv;
    fv0=M_current_eigenvector(:,1);
    scaled_M = (1./fv0) .* M .* fv0';
    scaled_factors = (1./fv0) .* ones(n_feature) .* fv0';
    
    t_obo=tic;
    %     tol_BCD=Inf;
    %     while tol_BCD>1e-5
    %         league_vec0=league_vec;
    
    total_bcd=0;
    [LP_A_sparse_i,LP_A_sparse_j,LP_A_sparse_s,LP_b,LP_lb,LP_ub] = optimization_M_LP_A_setting(n_feature,rho);
    obj_f=initial_objective;
    
    tol_NR=5e-1;
    tol_GD=5e-1;
    
    for BCD = 1:n_feature
        tbcd=tic;
        remaining_idx=1:n_feature;
        remaining_idx(BCD)=[];
        
        %if flag==0
        [ G ] = optimization_M_set_gradient( ...
            partial_sample, ...
            n_feature, ...
            c, ...
            M, ...
            y, ...
            nv_od, ...
            BCD, ...
            remaining_idx);
        %disp('touch');
        %end
        %G=[2*Gfull(remaining_idx,BCD);diag(Gfull)];
        
        %% BLUE or RED starts
        Ms_off_diagonal = scaled_M(remaining_idx,remaining_idx);
        %scaled_factors_v = scaled_factors(remaining_idx,BCD);
        scaled_factors_h = scaled_factors(BCD,remaining_idx);
        
        %Ms_off_diagonal(logical(eye(n_feature-1))) = 0;
        
        %% try BLUE league on NODE BCD
        league_vec_temp = league_vec;
        league_vec_temp(BCD) = 1; % BLUE is 1
        league_vec_remaining = league_vec_temp;
        league_vec_remaining(BCD) = [];
        
        [M_blue,...
            scaled_M_blue,...
            scaled_factors_blue,...
            M_current_eigenvector_blue,...
            min_obj_blue,...
            bins_blue,...
            num_list_blue,...
            LP_A_sparse_i,...
            LP_A_sparse_j,...
            LP_A_sparse_s,...
            LP_b,...
            LP_lb,...
            LP_ub,...
            LP_Aeq,...
            LP_beq,...
            zero_mask,...
            scaler_v,...
            remaining_idx,...
            lu_bound_idx] = optimization_M_Block_ns_cell_MLjournal_subgraph_gs_ws(1,league_vec,league_vec_temp,league_vec_remaining,...
            scaled_factors_h,...
            Ms_off_diagonal,...
            n_feature,...
            G,...
            M,...
            BCD,...
            remaining_idx,...
            M_current_eigenvector,...
            rho,...
            S_upper,...
            scaled_M,...
            scaled_factors,...
            bins,...
            obj_f,...
            tol_golden_search,...
            nv_od,...
            zz,...
            num_list,...
            partial_sample,...
            c,...
            y,...
            partial_observation,...
            options,...
            LP_A_sparse_i,...
            LP_A_sparse_j,...
            LP_A_sparse_s,...
            LP_b,...
            LP_lb,...
            LP_ub,...
            dia_idx,...
            tol_NR,...
            tol_GD,...
            GS_or_NR,...
            max_iter);
        
        %% try RED league on NODE BCD
        league_vec_temp(BCD) = -1; % RED is -1
        
        [M_red,...
            scaled_M_red,...
            scaled_factors_red,...
            M_current_eigenvector_red,...
            min_obj_red,...
            bins_red,...
            num_list_red] = optimization_M_Block_ns_cell_MLjournal_subgraph_gs_ws2(-1,league_vec,league_vec_temp,league_vec_remaining,...
            scaled_factors_h,...
            n_feature,...
            G,...
            M,...
            BCD,...
            remaining_idx,...
            M_current_eigenvector,...
            rho,...
            S_upper,...
            scaled_M,...
            scaled_factors,...
            bins,...
            obj_f,...
            tol_golden_search,...
            nv_od,...
            zz,...
            num_list,...
            partial_sample,...
            c,...
            y,...
            partial_observation,...
            LP_A_sparse_i,...
            LP_A_sparse_j,...
            LP_A_sparse_s,...
            LP_b,...
            LP_lb,...
            LP_ub,...
            LP_Aeq,...
            LP_beq,...
            zero_mask,...
            scaler_v,...
            lu_bound_idx,...
            options,...
            dia_idx,...
            tol_NR,...
            tol_GD,...
            GS_or_NR,...
            max_iter);
        
        if min_obj_red < min_obj_blue
            M = M_red;
            scaled_M = scaled_M_red;
            scaled_factors = scaled_factors_red;
            M_current_eigenvector = M_current_eigenvector_red;
            league_vec(BCD) = -1;
            bins = bins_red;
            num_list=num_list_red;
            obj_f=min_obj_red;
        end
        if min_obj_red > min_obj_blue
            M = M_blue;
            scaled_M = scaled_M_blue;
            scaled_factors = scaled_factors_blue;
            M_current_eigenvector = M_current_eigenvector_blue;
            league_vec(BCD) = 1;
            bins = bins_blue;
            num_list=num_list_blue;
            obj_f=min_obj_blue;
        end
        %% BLUE or RED ends
        total_bcd=total_bcd+toc(tbcd);
        %disp(['BCD: ' num2str(BCD) ' obj: ' num2str(obj_f) ' total_bcd: ' num2str(total_bcd)]);
    end
    %         current_objective = dml_obj(M, D);
    %         tol_BCD=norm(current_objective-initial_objective);
    %         disp(['one pass of BCD = ' num2str(current_objective)]);
    %         disp(['color difference = ' num2str(sum(abs(league_vec-league_vec0)))]);
    %         initial_objective=current_objective;
    %     end
    
    toc(t_obo);
    t_full=tic;
    
    [ G ] = optimization_M_set_gradient( ...
        partial_sample, ...
        n_feature, ...
        c, ...
        M, ...
        y, ...
        nv_full, ...
        0, ...
        0);
        
    tol_NR=5e-1;
    tol_GD=5e-1;
    
    [M] = optimization_M_ns_cell_MLjournal_subgraph_FULL_gs_ws(league_vec,...
        scaled_factors,...
        n_feature,...
        G,...
        M,...
        rho,...
        tol_golden_search,...
        obj_f,...
        S_upper,...
        nv_full,...
        zz,...
        partial_sample,...
        c,...
        y,...
        partial_observation,...
        options,...
        dia_idx,...
        tol_NR,...
        tol_GD,...
        GS_or_NR,...
        max_iter);
    
    toc(t_full);
    [ L ] = optimization_M_set_L_Mahalanobis( partial_sample, c, M );
    current_objective = partial_observation' * L * partial_observation;
    time_vec(time_i)=toc(tStart);
    obj_vec(time_i)=current_objective;
    disp(['mineig = ' num2str(min(eig(M)))]);
    disp(['converged = ' num2str(current_objective)]);
    disp(['total time = ' num2str(time_vec(time_i))]);
    
end

disp(['time_vec mean: ' num2str(mean(time_vec)) ' std:' num2str(std(time_vec))]);
disp(['obj_vec mean: ' num2str(mean(obj_vec)) ' std:' num2str(std(obj_vec))]);



[ L ] = optimization_M_set_L_Mahalanobis_tt( feature_train_test, M ); % full observation

if classifier_i==1 % 3-NN classifier
 knn_size = 3;
%========KNN classifier starts========
fl = class_train_test(initial_label_index);
fl(fl == -1) = 0;
x = KNN(fl, feature_train_test(initial_label_index,:), sqrtm(full(M)), knn_size, feature_train_test(~initial_label_index,:));
x(x==0) = -1;
x_valid = class_train_test;
x_valid(~initial_label_index) = x;
%=========KNN classifier ends=========   
elseif classifier_i==2 % Mahalanobis classifier
%=======Mahalanobis classifier starts========
z=mahalanobis_classifier(m,M,X);
x_valid=class_train_test;
x_valid(~initial_label_index)=z;
%========Mahalanobis classifier ends=========    
else % GLR-based classifier
%=======Graph classifier starts=======
cvx_begin
variable x(n_sample,1);
minimize(x'*L*x)
subject to
x(initial_label_index) == class_train_test(initial_label_index);
cvx_end
x_valid = sign(x);
%========Graph classifier ends========    
end

diff_label = x_valid - class_train_test;
error_classifier = size(find(diff_label~=0),1)*size(find(diff_label~=0),2)/size(class_test,1);
disp(['objective after metric learning : ' num2str(x_valid'*L*x_valid)]);
disp(['error rate after metric learning : ' num2str(error_classifier)]);

class_temp_binary = sign(x_valid);
class_temp_binary(initial_label_index) = [];

class_temp = zeros(size(class_temp_binary,1),size(class_temp_binary,2));
class_temp(class_temp_binary==1) = class_i;
class_temp(class_temp_binary==-1) = class_j;

end